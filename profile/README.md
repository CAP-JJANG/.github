 ![header](https://capsule-render.vercel.app/api?type=waving&color=gradient&height=300&section=header&text=CAPJJANG&fontSize=90&fontAlignY=40&desc=2023%20ê³µê°œ%20SW%20ê°œë°œì%20ëŒ€íšŒ&descAlign=70)

<br><br>
<div align="center">
  
[![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2FCap-JJANG&count_bg=%23000000&title_bg=%23000000&icon=github.svg&icon_color=%23FFFFFF&title=GitHub&edge_flat=false)](https://hits.seeyoufarm.com)
  
</div>
<br><br>

## :fire: ì œëª©
**[ENG]**  
Handwritten Acoustic Signal Recognition Technology Using Deep Learning (CSD-Model)

<br>

**[KOR]**  
Deep Learningì„ ì´ìš©í•œ ì†ê¸€ì”¨ ìŒí–¥ ì‹ í˜¸ ì¸ì‹ ê¸°ìˆ  (CSD-Model)

<br><br>
## :raised_hands: ì†Œê°œ
**[ENG]**   
Hello, This is Capjjang, participating in the 2023 Open SW Developer Contest.

When using a small wearable device in everyday life, the small keyboard panel sometimes makes the input uncomfortable. To address this inconvenience, the team wants to make the table a single panel. Instead of small screens, we have developed a Capjang Spectrogram Detection-Model (CSD-Model/Character Recognition Model through Sound Signal Detection) to enable the device to recognize the handwriting through the sound of writing on a wide table. 

  About 50 people recorded unique acoustic signals generated by writing alphabets on tables with Android voice recording, collecting about 900 acoustic data per class. We found a peak point where an explosive signal suddenly occurred in the collected dataset and implemented a function that cuts the acoustic file from the peak by one second. The sound file cut into 1 second was saved as a wave file and converted into a spectrogram, an image in the form of a time-frequency graph. 

  To augment the dataset, we converted the wave file into a spectrogram image after performing 1.25x and 1.50x speed to create x3x images of the original data. In addition, random masking was performed once, horizontally and vertically from the original spectrogram to create x3x images of the original data, augmenting the dataset to about 4500 per class. These images were converted into tensors and normalized to perform data preprocessing. We loaded CNN's Resnet-34 model to perform K-fold cross-validation, repeatedly learn the model for each fold, and then store the most accurate model (CSD-Model).

  The instrument records a handwritten acoustic signal every 1.5 seconds, stores the acoustic signal in a ByteRay object and sends the object to the server via RestAPI as a POST request. The server converts the Byte Array object received from the Client into a wave file and converts it to a spectrogram image. Apply the converted image to the CSD-Model to extract the result value and send a POST response to the Client.

  This technology can be used in a variety of fields, such as the development of the watch app "WRITE NOW" and the mobile app "RIGHT NOW." "WRITE NOW" is an application for watches that can recognize handwriting written on a desk and display it on the screen. Write "SOS" on your desk and press the check button to make an emergency call. You can also copy the written text and use it like a keyboard, and send a message. "RIGHT NOW" is a learning mobile application that recognizes children's handwritten sounds and scores English words.

<br>

**[KOR]**  
ì•ˆë…•í•˜ì„¸ìš”. 2023 ê³µê°œ SW ê°œë°œì ëŒ€íšŒì— ì°¸ê°€í•œ 'ìº¡ì§±'ì…ë‹ˆë‹¤.

ì¼ìƒ ì†ì—ì„œ ì†Œí˜• ì›¨ì–´ëŸ¬ë¸” ê¸°ê¸° ì‚¬ìš©ì‹œ, ì‘ì€ í‚¤ë³´ë“œ íŒ¨ë„ë¡œ ì¸í•´ ì…ë ¥ì— ë¶ˆí¸í•¨ì„ ëŠë‚„ ë•Œê°€ ìˆìŠµë‹ˆë‹¤. ë³¸ íŒ€ì€ ì´ëŸ¬í•œ ë¶ˆí¸í•¨ì„ í•´ì†Œí•˜ê¸° ìœ„í•´ í…Œì´ë¸”ì„ í•˜ë‚˜ì˜ íŒ¨ë„ë¡œ ë§Œë“¤ê³ ì í•©ë‹ˆë‹¤. ì‘ì€ í™”ë©´ ëŒ€ì‹ , ë„“ì€ í…Œì´ë¸”ì—ì„œ ê¸€ì”¨ ì“°ëŠ” ìŒí–¥ì„ í†µí•´ ê¸°ê¸°ì—ì„œ ê·¸ ê¸€ì”¨ë¥¼ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡ CSD-Model(Capjjang Spectrogram Detection-Model/ìŒí–¥ ì‹ í˜¸ ê°ì§€ë¥¼ í†µí•œ ë¬¸ì ì¸ì‹ ëª¨ë¸)ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. 

  ì•½ 50ëª…ì˜ ì‚¬ëŒë“¤ì„ í†µí•´ Android ìŒì„±ë…¹ìŒ ê¸°ëŠ¥ìœ¼ë¡œ í…Œì´ë¸” ìœ„ì—ì„œ ì•ŒíŒŒë²³(ì†Œë¬¸ì)ì„ ì¼ì„ ë•Œ ìƒê¸°ëŠ” ê³ ìœ í•œ ìŒí–¥ ì‹ í˜¸ë¥¼ ë…¹ìŒí•˜ì—¬, í´ë˜ìŠ¤ë‹¹ ì•½ 900ê°œì˜ ìŒí–¥ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤. ìˆ˜ì§‘í•œ ë°ì´í„°ì…‹ì—ì„œ ê°‘ìê¸° í­ë°œì ì¸ ì‹ í˜¸ê°€ ë°œìƒí•˜ëŠ” Peak ì§€ì ì„ ì°¾ì•„ Peak ë¶€í„° ìŒí–¥íŒŒì¼ì„ 1ì´ˆë¥¼ ìë¥´ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. 1ì´ˆë¡œ ì˜ë¼ì§„ ìŒí–¥íŒŒì¼ì„ wav íŒŒì¼ë¡œ ì €ì¥í•˜ê³ , ì‹œê°„-ì£¼íŒŒìˆ˜ ê·¸ë˜í”„ í˜•íƒœì˜ ì´ë¯¸ì§€ì¸ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ìœ¼ë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤. 

  ë°ì´í„°ì…‹ ì¦ê°•ì„ ìœ„í•´, wav íŒŒì¼ì„ 1.25ë°°ì†, 1.50 ë°°ì†ì„ ì§„í–‰í•œ í›„ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì—¬ ì›ë³¸ ë°ì´í„°ì˜ x3ë°° ì´ë¯¸ì§€ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼, ì›ë³¸ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ì—ì„œ ê°€ë¡œ, ì„¸ë¡œ í•œ ë²ˆì”© ëœë¤ ë§ˆìŠ¤í‚¹ì„ ì§„í–‰í•˜ì—¬ ì›ë³¸ë°ì´í„°ì˜ x3ë°° ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì—¬ í´ë˜ìŠ¤ë‹¹ ì•½ 4500ê°œë¡œ ë°ì´í„°ì…‹ì„ ì¦ê°•í–ˆìŠµë‹ˆë‹¤. ì´ ì´ë¯¸ì§€ë“¤ì„ tensorë¡œ ë³€í™˜í•˜ê³ , ì •ê·œí™”ë¥¼ ì§„í–‰í•˜ì—¬ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì§„í–‰í–ˆìŠµë‹ˆë‹¤. CNNì˜ Resnet-34 ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ K-fold êµì°¨ ê²€ì¦ì„ ì§„í–‰í•˜ê³ , ê° í´ë“œì— ëŒ€í•´ ë°˜ë³µì ìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµí•œ í›„ ìµœê³  ì •í™•ë„ë¥¼ ê°€ì§„ ëª¨ë¸(CSD-Model)ì„ ì €ì¥í•˜ë„ë¡ í–ˆìŠµë‹ˆë‹¤.

  ê¸°ê¸°ë¥¼ ì´ìš©í•´ 1.5ì´ˆë§ˆë‹¤ ì†ê¸€ì”¨ ìŒí–¥ ì‹ í˜¸ë¥¼ ë…¹ìŒí•˜ì—¬ ByteArray ê°ì²´ì— í•´ë‹¹ ìŒí–¥ì‹ í˜¸ë¥¼ ì €ì¥í•˜ì—¬ RestAPIë¥¼ í†µí•´ Serverë¡œ í•´ë‹¹ ê°ì²´ë¥¼ POST ìš”ì²­ìœ¼ë¡œ ë³´ëƒ…ë‹ˆë‹¤. Serverì—ì„œëŠ” Clientë¡œë¶€í„° ë°›ì€ ByteArrayê°ì²´ë¥¼ wav íŒŒì¼ë¡œ ë³€í™˜í•œ ë’¤, ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ë³€í™˜ëœ ì´ë¯¸ì§€ë¥¼ CSD-Modelì— ì ìš©ì‹œì¼œ ê²°ê³¼ê°’ì„ ì¶”ì¶œí•˜ì—¬ Clientì—ê²Œ POST ì‘ë‹µì„ ë³´ëƒ…ë‹ˆë‹¤.

  ì´ ê¸°ìˆ ì€ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë  ìˆ˜ ìˆìœ¼ë©°, ê·¸ ì˜ˆì‹œë¡œ ì›Œì¹˜ìš© ì–´í”Œ â€œWriteNowâ€ì™€ ëª¨ë°”ì¼ ì–´í”Œ â€œRightNowâ€ë¥¼ ê°œë°œí–ˆìŠµë‹ˆë‹¤. â€œWriteNowâ€ëŠ” ì›Œì¹˜ìš© ì–´í”Œë¡œ ì±…ìƒì—ì„œ ì“´ ì†ê¸€ì”¨ë¥¼ ì¸ì‹í•˜ì—¬ í™”ë©´ì— ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. â€œsosâ€ë¼ê³  ì±…ìƒì— ì“°ê³  ì²´í¬ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ê¸´ê¸‰ ì „í™”ë¥¼ ê±¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì¨ì§„ ê¸€ì”¨ë¥¼ ë³µì‚¬í•˜ì—¬ í‚¤ë³´ë“œì²˜ëŸ¼ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ë©”ì‹œì§€ë„ ë³´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. â€œRightNowëŠ” ì•„ì´ë“¤ì˜ ì†ê¸€ì”¨ ìŒí–¥ì„ ì¸ì‹í•˜ì—¬ ì˜ë‹¨ì–´ë¥¼ ë§ê²Œ ì¼ëŠ”ì§€ ì±„ì í•˜ëŠ” í•™ìŠµìš© ëª¨ë°”ì¼ ì–´í”Œì…ë‹ˆë‹¤.


<br><br>
## âœ¨ ê¸°ëŒ€ íš¨ê³¼
**[ENG]**
1. Various applications: It can be used in a variety of fields, including improved user interface based on letter input, handwriting recognition system, and handwriting-based automatic translation and recognition technology.
2. Convenient input method: Instead of a keyboard or touch screen, you can convert it into an acoustic signal and input it by handwriting.
3. Improve accessibility: Improve access to information for users with voice or motion difficulties. Blind people or people with physical constraints can also recognize handwritten information by converting it into sound, allowing various users to freely access the information.

<br>

**[KOR]**
1. ë‹¤ì–‘í•œ ì‘ìš© ë¶„ì•¼: ê¸€ì ì…ë ¥ ê¸°ë°˜ì˜ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ê°œì„ , í•„ê¸°ì¸ì‹ ì‹œìŠ¤í…œ, ì†ê¸€ì”¨ ê¸°ë°˜ì˜ ìë™ë²ˆì—­ ë° ì¸ì‹ê¸°ìˆ  ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. í¸ë¦¬í•œ ì…ë ¥ ë°©ì‹ ì œê³µ: í‚¤ë³´ë“œë‚˜ í„°ì¹˜ìŠ¤í¬ë¦° ëŒ€ì‹  ì†ìœ¼ë¡œ ì§ì ‘ ê¸€ìë¥¼ ì“°ëŠ” ë™ì‘ì„ í†µí•´ ìŒí–¥ì‹ í˜¸ë¡œ ë³€í™˜í•˜ì—¬ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. ì ‘ê·¼ì„± ê°œì„ : ìŒì„±ì´ë‚˜ ë™ì‘ì— ì–´ë ¤ì›€ì´ ìˆëŠ” ì‚¬ìš©ìë“¤ì—ê²Œ ì •ë³´ ì ‘ê·¼ì„±ì„ ê°œì„ í•´ì¤ë‹ˆë‹¤. ì‹œê° ì¥ì• ì¸ì´ë‚˜ ì‹ ì²´ì  ì œì•½ì´ ìˆëŠ” ì‚¬ëŒë“¤ë„ ì†ê¸€ì”¨ë¡œ í‘œí˜„ëœ ì •ë³´ë¥¼ ì†Œë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ì¸ì‹í•  ìˆ˜ ìˆì–´, ë‹¤ì–‘í•œ ì‚¬ìš©ìë“¤ì´ ì •ë³´ì— ììœ ë¡­ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


<br><br>
## ğŸ’ªÂ ì£¼ìš” ê¸°ëŠ¥
### âœ”ï¸ MakeDataset
Details in [MakeDataset Repository](https://github.com/CAP-JJANG/MakeDataset)  

<br>

### âœ”ï¸ CSD-Model
**[ENG]**
1. Set up the GPU usage environment in PyTorch.
2. Configure transformations that define data preprocessing and normalization for input images.
3. Define the dataset and apply the data transform.
4. Create an image classification model using the ResNet-34 architecture.
5. Apply L2 normalization.
6. K-Fold cross-validation learns the model and evaluates its performance.
7. Save the model weight if you have the highest accuracy per fold.
8. Save the learning and test results to a file.

**[KOR]**
1. PyTorchì—ì„œ GPU ì‚¬ìš© í™˜ê²½ì„ ì„¤ì •í•©ë‹ˆë‹¤.
2. ì…ë ¥ ì´ë¯¸ì§€ì— ëŒ€í•œ ë°ì´í„° ì „ì²˜ë¦¬ ë° ì •ê·œí™”ë¥¼ ì •ì˜í•˜ëŠ” ë³€í™˜ì„ êµ¬ì„±í•©ë‹ˆë‹¤.
3. ë°ì´í„°ì…‹ì„ ì •ì˜í•˜ê³ , ë°ì´í„° ë³€í™˜ì„ ì ìš©í•©ë‹ˆë‹¤.
4. ResNet-34 ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
5. L2 ì •ê·œí™”ë¥¼ ì ìš©í•©ë‹ˆë‹¤.
6. K-Fold êµì°¨ ê²€ì¦ì„ í†µí•´ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
7. í´ë“œë³„ ìµœê³  ì •í™•ë„ë¥¼ ê°€ì§„ ê²½ìš° ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
8. í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤.

<br>

### âœ”ï¸ CSD-Server
Details in [CSD-Server Repository](https://github.com/CAP-JJANG/CSD-Server) 

<br>

### âœ”ï¸ RightNow
Details in [RightNow Repository](https://github.com/CAP-JJANG/RightNow) 

<br>

### âœ”ï¸ WriteNow
Details in [WriteNow Repository](https://github.com/CAP-JJANG/WriteNow)  

<br><br>
## ğŸ¦¾ ì£¼ìš” ê¸°ìˆ 
### âœ”ï¸ MakeDataset
**Dataset**  
* PyCharm IDE
* Python: 3.9.13
* Librosa: 0.10.1
* Matplotlib: 3.7.2
* Numpy: 1.25.2
* Pillow: 10.0.1
* Pydub: 0.25.1

<br>
  
### âœ”ï¸ CSD-Model
**Model - CNN**
* PyCharm IDE
* Python 3.9.13
* Scikit_learn 1.3.1
* Torch 1.13.1
* Torchvision 0.14.1

<br>

### âœ”ï¸ CSD-Server
**Server - Django**
* PyCharm: IDE
* Python: 3.9.13
* Django: 4.2.5
* Djangorestframework: 3.14.0
* Librosa: 0.10.1
* Matplotlib: 3.7.2
* Numpy: 1.25.2
* Pillow: 10.0.1
* Pydub: 0.25.1
* Torch: 1.13.1
* Torchvision: 0.14.1

<br>

### âœ”ï¸ RightNow
**Mobile - Android**
* Android Studio: Giraffe | 2022.3.1
* Gradle plugin: 8.1.1
* JDK: jbr-17
* Min SDK: 24
* Target SDK: 33
* Navigation : 2.7.3
* Retrofit: 2.9.0
  
<br>

### âœ”ï¸ WriteNow
**Mobile - Android**
* Android Studio: Giraffe | 2022.3.1
* Gradle plugin: 8.1.1
* JDK: jbr-17
* Min SDK: 30
* Target SDK: 33
* Retrofit: 2.9.0
* Livedata: 2.6.2
* Eventbus: 3.3.1


<br><br>
## ğŸ§¬ ëª¨ë¸ ì•„í‚¤í…ì²˜
<div align="center">
  <img width="60%" alt="image" src="https://github.com/CAP-JJANG/.github/assets/92065911/7fcd5810-2541-4a52-a0aa-a758c61e8fc8">
</div>

<br><br>
## ğŸ”— ì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜
<div align="center">
  <img width="80%" alt="image" src="https://github.com/CAP-JJANG/.github/assets/92065911/1b391640-4450-4db0-a662-e403e101600a">
</div>

<br><br>
## ğŸ‘€ ì‹¤í–‰ í™”ë©´
* **Watch** :watch:
  <img width="100%" alt="image" src="https://github.com/Capjjang23/.github/assets/92065911/08fb70df-859d-4dca-ad84-6ca1ef4a6520">
  <br>
* **Phone** :iphone:
  <img width="100%" alt="image" src="https://github.com/Capjjang23/.github/assets/92065911/3acf80b7-fa8d-4b8d-aadf-1066ba7d8a7f">

<br><br>
## ğŸ¤ ì»¤ë°‹ ë£°

| ì»¤ë°‹ êµ¬ë¶„ | ì„¤ëª… |
| --- | --- |
| FEAT | (Feature) ê°œì„  ë˜ëŠ” ê¸°ëŠ¥ ì¶”ê°€ |
| BUG | (Bug Fix) ë²„ê·¸ ìˆ˜ì • |
| DOC | (Documentation) ë¬¸ì„œ ì‘ì—… |
| TST | (Test) í…ŒìŠ¤íŠ¸ ì¶”ê°€/ìˆ˜ì • |
| BLD | (Build) ë¹Œë“œ í”„ë¡œì„¸ìŠ¤ ê´€ë ¨ ìˆ˜ì •(yml) |
| PERF | (Performance) ì†ë„ ê°œì„  |
| CLN | (Cleanup) ì½”ë“œ ì •ë¦¬/ë¦¬íŒ©í† ë§ |

- `ì»¤ë°‹ êµ¬ë¶„/~í•œë‹¤`ëŠ” ëª…ë ¹ì–´ë¡œ ì‹œì‘í•˜ì—¬ í•œ ëˆˆì— ì–´ë–¤ ì‘ì—…ì„ í–ˆëŠ”ì§€ ì•Œê¸° ì‰½ê²Œ ì ëŠ”ë‹¤.
- ì˜ˆì‹œ  
  `FEAT/Create~`, `FEAT/Add~`, `BUG/Fix~`, `DOC/Delete~`


<br><br>
## ğŸ‘» íŒ€ì›
<table>
  <tr> 
    <td><a href="https://github.com/Ga-Long"><img src="https://avatars.githubusercontent.com/u/100428958?v=4" style="width:150%; height:150%;"></a></td>
    <td><a href="https://github.com/kimgwon"><img src="https://avatars.githubusercontent.com/u/92065911?v=4"></a></td>
    <td><a href="https://github.com/youngchive"><img src="https://avatars.githubusercontent.com/u/102659915?v=4"></a></td>
    <td><a href="https://github.com/mmihye"><img src="https://avatars.githubusercontent.com/u/92644651?v=4"></a></td>
  </tr>
  <tr> 
    <td align='center'><strong>ì´ê°€í˜„</strong></td> 
    <td align='center'><strong>ê¹€ì§€ì›</strong></td> 
    <td align='center'><strong>ì¡°ì„œì˜</strong></td> 
    <td align='center'><strong>ì„ë¯¸í˜œ</strong></td> 
  </tr>
</table>

<br><br>
## ğŸ¤–Â ë¼ì´ì„¼ìŠ¤
* MakeDataset : Apache-2.0 license
* CSD-Model : Apache-2.0 license
* CSD-Server : Apache-2.0 license
* RightNow : Apache-2.0 license
* WriteNow : Apache-2.0 license
